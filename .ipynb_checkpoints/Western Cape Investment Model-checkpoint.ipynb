{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MLG382 GROUP PROJECT  [100 Marks] \n",
    "**Lecturer: _K. Igwe_**\n",
    "\n",
    "\n",
    "# Your task is to predict *median house values* in Western cape, given a number of features from the districts \n",
    "\n",
    "\n",
    "The first question to ask before building a model is what exactly the business objective is. How does the client expect to use and benefit from the model? The objective is important in determining how you will frame the problem, the algorithms to select, the performance measure to use for your model evaluation, and the level of effort you will spend tweaking your model.\n",
    "\n",
    "In this project, you should assume that your model’s output (a prediction of a district’s median housing price) will be fed to\n",
    "another Machine Learning system along with many other determinats to better understand the risk of investing in a given area of the Western Cape. The data (home.csv) are provided alonside this notebook. \n",
    "\n",
    "This checklist can guide you through the projects.\n",
    "1. Frame the problem and look at the big picture (done for you).\n",
    "2. Get the data (made available for you).\n",
    "3. Explore the data to gain insights.\n",
    "4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms.\n",
    "5. Explore many different models and shortlist the best ones.\n",
    "6. Fine-tune your models and combine them into a great solution.\n",
    "7. Present your solution.\n",
    "\n",
    "### Aim\n",
    "- Lecturers aim: To expose you to practical applications of ML. \n",
    "- Your aim:  to predict median house values in Western cape, given a number of features from the province. \n",
    "\n",
    "### Skills Tested\n",
    "- Basic Python Programming\n",
    "- EDA\n",
    "- Use of sklearn Library\n",
    "- choosing the right model and Building a classification Model\n",
    "- Understanding and using different evaluation techniques\n",
    "- Reporting \n",
    "\n",
    "### Instructions and Directions\n",
    "1. _**your code here**_  or  _**your answer here**_ need to be deleted and replaced with your code or answer\n",
    "2. You may use more than one cell to answer a question\n",
    "3. Ensure that you include appropriate comment\n",
    "4. If your code requires special instruction or dependencies to run, please provide these in your submission \n",
    "\n",
    "### NOTE: 80% is for meeting requirement, 20% will be awarded based on extra work. I have provided some guide where I enticipate that you may need extra help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUP MEMBERS:\n",
    "#### Werner Pretorius\n",
    "#### Zandrei Kleynhans\n",
    "#### Lourens Geyser\n",
    "#### De Wet Kirsten\n",
    "#### Gideon Rossouw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUBRIC\n",
    "\n",
    "1. Frame the problem and look at the big picture (done for you).\n",
    "2. Get the data (made available for you).\n",
    "3. Explore the data to gain insights.\n",
    "4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms.\n",
    "5. Explore many different models (at least 3) and shortlist the best ones.\n",
    "6. Fine-tune your models.\n",
    "7. Present your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Frame the problem and look at the big picture (done for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing Required here. Good Luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maths Stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "\n",
    "# Plotting Stuff\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing Stuff\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Performance Metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# To calculate class weights => combat label imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data (made available for you) [0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First things first, let's import the CSV to get a feel of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n"
     ]
    }
   ],
   "source": [
    "home_data = pd.read_csv(\"home.csv\")\n",
    "print(home_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doctor the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             0.000000\n",
      "latitude              0.000000\n",
      "housing_median_age    0.000000\n",
      "total_rooms           0.000000\n",
      "total_bedrooms        1.002907\n",
      "population            0.000000\n",
      "households            0.000000\n",
      "median_income         0.000000\n",
      "median_house_value    0.000000\n",
      "ocean_proximity       0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "null_percentage = home_data.isnull().sum()/len(home_data)*100\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data.drop(columns=[\"total_bedrooms\"])\n",
    "\n",
    "home_data.dropna(inplace=True)\n",
    "home_data.drop_duplicates(inplace=True)\n",
    "\n",
    "home_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data to gain insights [10] BONUS [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hints!\n",
    "- check for correlations: features with the label. And features with one another\n",
    "- use graphs to illustrate similarities and differences as you deem neccessary\n",
    "- NOTE: Features with non-linear relationships will have little or no correlation but may still be very instrumental in your predictions\n",
    "- Test combinations of features (for example, new feature = old_feature1/old_feature2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A bit of One-Hot Encoding on Ocean Proximity => Because our machines speak in 1's and 0's, not words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "few categories => OHE is most appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(home_data[\"ocean_proximity\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOS UIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dummies to create one new column for every category => creates DataFrame\n",
    "ohe_prox = pd.get_dummies(home_data[\"ocean_proximity\"])\n",
    "\n",
    "# add to existing dataset\n",
    "home_data = home_data.join(ohe_prox).drop(columns=[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we must visualise the Feature to Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first we build a matrix that contains the Pearson Correlation Coefficient (PCC) between features with reference to the labels\n",
    "corr_matrix_feats = home_data.drop(columns=[\"median_house_value\"]).corr()\n",
    "\n",
    "# next, we isolate the feature column in the matrix that corresponds to the labels\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# then generate a heatmap to see the correlations of features against the labels => based on the data we just isolated\n",
    "sns.heatmap(corr_matrix_feats, annot = True, cmap = \"RdBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we visualise the Feature to Target Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first we build a matrix that contains the Pearson Correlation Coefficient (PCC) between features with reference to the labels\n",
    "corr_matrix = home_data.corr()\n",
    "\n",
    "# next, we isolate the feature column in the matrix that corresponds to the labels\n",
    "corr_matrix_labels = corr_matrix[[\"median_house_value\"]].drop(labels=[\"median_house_value\"])\n",
    "\n",
    "# then generate a heatmap to see the correlations of features against the labels => based on the data we just isolated\n",
    "sns.heatmap(corr_matrix_labels, annot = True, fmt=\"0.3\", cmap = \"RdBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data to better expose the underlying data patterns to Machine Learning algorithms [20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hint!\n",
    "- remove the corresponding districts.\n",
    "- remember to deal with th NA's (you can as well do this before now)\n",
    "- Scale, Normalize, transform some features (e.g., median income can be put into categroies).\n",
    "- Set the values to some value (zero, the mean, the median, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Features with High Feature to Feature Correlarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain features with their scores\n",
    "scores = corr_matrix_labels.reset_index()\n",
    "\n",
    "# order the scores in descending order\n",
    "scores_ordered = scores.reindex(scores[\"median_house_value\"].abs().sort_values(ascending=False).index)\n",
    "\n",
    "# get the ordered feature names\n",
    "features_ordered = list(scores_ordered[\"index\"])\n",
    "\n",
    "# Assess the Correlations and decise on which Redundant Columns to drop => pass string names into list\n",
    "redundancies = [\"longitude\", \"population\", \"total-rooms\"]\n",
    "\n",
    "# Drop those redundant columns\n",
    "features_cleaned = [feature for feature in features_ordered if feature not in redundancies]\n",
    "\n",
    "# gather all those cleaned features into a dataframe\n",
    "features_df = home_data[features_cleaned]\n",
    "\n",
    "# lets bring everything together => just to make sure our features and targets are still on the same page\n",
    "home_cleaned = features_df.join(home_data[\"median_house_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(50,20))\n",
    "# plt.scatter(home_cleaned[\"median_house_value\"], home_cleaned[\"median_house_value\"], alpha =0.4 )\n",
    "sns.set_theme(style=\"dark\") \n",
    "ax = sns.boxplot(x=home_cleaned[\"total_rooms\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Explore many different models (at least 3) and shortlist the best ones [20] Bonus [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hint!\n",
    "- Some with cross_validation\n",
    "- Tree based models\n",
    "- Non- Tree based Models\n",
    "- (don't worry too much about tuning here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _your code here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Fine-tune your models [10] BONUS [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hint!\n",
    "- We manually tuned our model in the class (this is not efficient)\n",
    "\n",
    "try:\n",
    "- GridSearchCV from sklearn (self-improvement)\n",
    "- esemble methods\n",
    "- evaluate your models on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _your code here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present your solution [20]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hint!\n",
    "- you do not need machine learning knowledge to write a report\n",
    "- Report your choosen solution and justify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _your Report here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADVISE: Let your objective not be to obtain marks but to understand, experiment and experience! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! You have achieved a lot if you have completed this project deligently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
